{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d8c1f5-2dc8-4d8c-9b87-34a3850fc539",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "1. Put the images you want to process in `./images/`. This is already prepopulated with several images organized by language\n",
    "2. Run the notebook\n",
    "\n",
    "### On Colab?\n",
    "\n",
    "Run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1386df22-9315-4e26-9689-62f98fa8dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "!git clone https://github.com/alexcg1/scenex-tests\n",
    "os.chdir('scenex-tests')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be48c872-4acb-4b07-868d-c8cb408aa7b1",
   "metadata": {},
   "source": [
    "### Load API keys\n",
    "\n",
    "If you have `dotenv` installed and a `.env` file, the below code will load it from there. Otherwise you'll need to set `SCENEX_SECRET` and `OPENAI_API_KEY` environment variables manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e8af7257-3d0b-4dde-a39b-f2909b164cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded from .env\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    print(\"Environment variables loaded from .env\")\n",
    "except ImportError:\n",
    "    os.environ['OPENAI_API_KEY'] = \"<your OpenAI key>\"\n",
    "    os.environ['SCENEX_SECRET'] = \"<your SceneXplain key>\"\n",
    "    # print(\"Please set OPENAI_API_KEY and SCENEX_SECRET environment variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ffb26e-09e9-418a-850f-556e3616c449",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Pre-process images\n",
    "\n",
    "Convert all `webp` files to `jpeg`\n",
    "\n",
    "**Note:** No need to do this for existing images in repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ae4228-e64d-456f-a8e8-2f0db4f0c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !find ./images -type f -name \"*.webp\" -exec mogrify -format jpeg {} \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690a5191-761c-470c-8400-ae356a64a8ad",
   "metadata": {},
   "source": [
    "## Generate image list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1c4c1c5d-b46d-4e93-a7f4-c9669820dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "image_files = glob('./images/**/*.jpeg')  # just test a few for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67282c3-31bb-4956-bb88-5a13ba090246",
   "metadata": {},
   "source": [
    "## Define functions for SceneXplain and OpenAI I/O"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa1ee1-1179-4d8e-976b-3fbe003b2f23",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### SceneXplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf66d9f-587d-4d48-ba45-89e204f1999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import json\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cba9391b-6024-4f70-8fd2-088f49f47549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SceneX setup and functions\n",
    "\n",
    "SCENEX_SECRET=os.getenv('SCENEX_SECRET')\n",
    "\n",
    "scenex_headers = {\n",
    "    \"x-api-key\": f\"token {SCENEX_SECRET}\",\n",
    "    \"content-type\": \"application/json\",\n",
    "}\n",
    "\n",
    "ALGO = \"Jelly\"\n",
    "\n",
    "def image_to_data_uri(file_path):\n",
    "    with open(file_path, \"rb\") as image_file:\n",
    "        encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "        return f\"data:image/png;base64,{encoded_image}\"\n",
    "        \n",
    "def generate_scenex_data(image_files, json_schema=None, question=None, features=[]):\n",
    "    data = {}\n",
    "    data['data'] = []\n",
    "\n",
    "    for file in image_files:\n",
    "        cid = file.split('/')[-1]\n",
    "        row = {\n",
    "            \"image\": image_to_data_uri(file),\n",
    "            \"features\": features,\n",
    "            \"algorithm\": ALGO,\n",
    "            \"cid\": cid\n",
    "        }\n",
    "\n",
    "        if question:\n",
    "            row[\"question\"] = question\n",
    "\n",
    "        if json_schema:\n",
    "            row[\"json_schema\"] = json_schema\n",
    "\n",
    "        data['data'].append(row)\n",
    "\n",
    "    return data\n",
    "\n",
    "def process_scenex(data):\n",
    "    connection = http.client.HTTPSConnection(\"api.scenex.jina.ai\")\n",
    "    connection.request(\"POST\", \"/v1/describe\", json.dumps(data), scenex_headers)\n",
    "    response = connection.getresponse()\n",
    "    response_data = response.read().decode(\"utf-8\")\n",
    "    \n",
    "    connection.close()\n",
    "\n",
    "    return json.loads(response_data)['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b3dfc0-f77b-4d76-b056-b4d5fe71da3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0252a3-bede-4d54-9b56-30bd84582498",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c8088723-5c21-4f2c-af01-765348c13823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI functions\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def encode_openai_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def generate_openai_data(image_files, text=\"\"):\n",
    "    output = []\n",
    "    \n",
    "    for file in image_files:\n",
    "        base64_image = f\"data:image/jpeg;base64,{encode_openai_image(file)}\"\n",
    "        data = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                # \"filename\": file,\n",
    "                 \"content\": [\n",
    "                    {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": base64_image\n",
    "                    },\n",
    "                    {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": text\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        output.extend(data)\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "def process_openai(data):\n",
    "    output = []\n",
    "\n",
    "    for record in data:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-vision-preview\",\n",
    "            messages=[record],\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "\n",
    "        output.append(response.choices[0])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef2f7e3-42cb-46c9-9ade-b88e544685ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Basic captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb46c8-dbaa-480e-bb9b-e5dbc8453cb0",
   "metadata": {},
   "source": [
    "### SceneXplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabfedcd-8df9-4b4e-b392-da43c703e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_data = generate_scenex_data(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103b2820-2393-448c-9247-84b7af67d2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response = process_scenex(scenex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599146aa-57cb-419f-8afc-e718ca6d248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869556e5-10db-4c65-bd0b-516e85863866",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb5faa4-5753-4628-a41d-b60faf7442e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_data = generate_openai_data(image_files, \"what is in this image?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286be171-bdf7-4e5c-b16f-695109bea6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response = process_openai(openai_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d5d20-981d-4c01-8887-7d68837b6f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df646e-0784-4d59-8705-63e29329a975",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Visual question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba35725b-f587-4222-9e48-a461fc11da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'what does the text say in this image?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7885bd69-b20b-4a91-ac64-519995141843",
   "metadata": {},
   "source": [
    "### SceneXplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef268f-1fc6-4dd3-a277-92310569ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['question_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae18ec38-cc56-46b2-9bd8-ad31363601e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_data = generate_scenex_data(image_files, question=question, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c34f9b-c7c3-4608-96ad-0fa6e0090456",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response = process_scenex(scenex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99537e4d-ae3d-4cd6-95c8-eb8cb97db335",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed72dd62-d4d1-4be4-8001-b92459a78ce6",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe5cf36-87f8-45f1-8cd2-1c1d2549e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_data = generate_openai_data(image_files, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dccc86-b93a-4ad8-bb84-4ae037dd1c8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "openai_response = process_openai(openai_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0791a6ef-f2aa-431d-9da9-fbb9d531b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4337351-0307-4388-a5f0-a13d76c4f47b",
   "metadata": {},
   "source": [
    "## Extract JSON from image\n",
    "\n",
    "We'll use SceneXplain's \"Extract JSON from Image\" feature to extract each text string and output to JSON that fits a strict schema.\n",
    "\n",
    "We'll also try a klugy way to do this with OpenAI, in the interests of fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "021121c2-9f5a-425f-b57a-868ed9fc96fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = {\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"text_strings\": {\n",
    "      \"type\": \"array\",\n",
    "      \"description\": \"Every text string contained in the image. Consider all languages\"\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378ef9a-336f-41b4-8e74-caa63df82f10",
   "metadata": {},
   "source": [
    "### SceneX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5e4cc3fa-0792-4ba4-96c2-e287fb7c790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"json\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "78393558-5a7e-44ed-9c01-e271263a034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_data = generate_scenex_data(image_files, json_schema=json.dumps(json_schema), features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "36f45bf1-5b39-43f1-9afb-3899daf22783",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response = process_scenex(scenex_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0aff10-0363-438f-96ee-4848b99194ff",
   "metadata": {},
   "source": [
    "### OpenAI\n",
    "\n",
    "We have to kluge it a bit by asking for JSON output as part of the question. This may not always provide reliably strict output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d2b62a39-0649-4fa9-bf34-40fe4b2a039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = f\"Extract the text strings from this image and populate a JSON that follows this schema:\\n\\n{str(json_schema)}. Return just the output JSON. Do not put it in a code block\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "057fe81a-cfd1-484a-babe-64bfbad4a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_data = generate_openai_data(image_files, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6cc46cfe-c570-4f60-80e4-f4a60d32cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response = process_openai(openai_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baecfc6c-3513-4421-ae67-e5a0777aaba8",
   "metadata": {},
   "source": [
    "### Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d924534b-185f-4c5b-9a1a-4763d4f39651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images/ko/pexels-photo-5051602.jpeg\n",
      "SceneXplain: \t{'text_strings': ['삼부식육점', '号号 号, 番号 7▲ 1.244-3800', '15']}\n",
      "OpenAI:\t\t{'text_strings': ['삼부', '전구', '디오', '문구', '생활용품', '금구', '도매', '1244-3800']}\n",
      "----------\n",
      "./images/ko/pexels-photo-6314649.jpeg\n",
      "SceneXplain: \t{'text_strings': ['|야', '좋은 날에 만나', '단이 방', '50', '좋은 나를 만나']}\n",
      "OpenAI:\t\t{'text_strings': ['삶은 날에 만나', '삶은 나를 만나', '닷이 발다']}\n",
      "----------\n",
      "./images/cn/pexels-photo-704379.jpeg\n",
      "SceneXplain: \t{'text_strings': ['饒河街觀光夜市', 'Raohe St. Night Market', '歡', '光', '健', '媽祖廟口', '服務台', '金瑞刊', '康']}\n",
      "OpenAI:\t\t{'text_strings': ['饒河街觀光夜市', 'Raohe St. Night Market', 'GOOD', '綜合果汁', '招牌麵線', 'QQ', '臭豆腐']}\n",
      "----------\n",
      "./images/cn/pexels-photo-5765624.jpeg\n",
      "SceneXplain: \t{'text_strings': ['宇', '川']}\n",
      "OpenAI:\t\t{'text_strings': ['京都嵐山']}\n",
      "----------\n",
      "./images/cn/pexels-photo-2670327.jpeg\n",
      "SceneXplain: \t{'text_strings': ['金钱肚20元', '旺角牛筋腩20元', '旺角牛杂18元']}\n",
      "OpenAI:\t\t{'text_strings': ['魚丸湯', '20元', '貢丸', '20元', '丸仔湯', '18元']}\n",
      "----------\n",
      "./images/cn/pexels-photo-2599543.jpeg\n",
      "SceneXplain: \t{'text_strings': ['為人演說不取於相如如', '持讀誦為人演說其福勝', '此經乃至四句', '『無量阿僧祗世界七', '不生活相發菩提', '句法應不是', '阿熊多羅二', '言法相酱如', '是見如是信解']}\n",
      "OpenAI:\t\t{'text_strings': ['博爱之门深处的暗号', '此日又是罗家祭日', '今日天朗气清且晴又好', '兄弟群赴西域长安道上', '任凭那风吹雨打不误前行', '多谢路过相知之士加持', '出门前听闻杜牧诗句贴门口', '嘱咐无论如何来路', '莫将他语与讲真假', '因为我们只信赏善罚恶', '冥冥中自有旨意', '命中注定会相会', '又岂在朝朝暮暮']}\n",
      "----------\n",
      "./images/cn/pexels-photo-3603453.jpeg\n",
      "SceneXplain: \t{'text_strings': ['老门框卤煮店', '老门框廣為心明', '王', '1', '卤']}\n",
      "OpenAI:\t\t{'text_strings': ['老门框炸酱面', '牛肉', '炒肝', '面食', '小吃']}\n",
      "----------\n",
      "./images/ja/free-photo-of-prohibition-sign-in-japanese.jpeg\n",
      "SceneXplain: \t{'text_strings': ['No Smoking', '禁止吸烟', '路上喫煙禁止区域']}\n",
      "OpenAI:\t\t{'text_strings': ['ポイ捨てご遠慮ください', 'LITTERING', '禁煙', 'NO SMOKING']}\n",
      "----------\n",
      "./images/ja/free-photo-of-illuminated-lantern-in-the-street.jpeg\n",
      "SceneXplain: \t{'text_strings': ['キリンラカー', 'こてつ象', '美子専門店']}\n",
      "OpenAI:\t\t{'text_strings': ['串カツ田中', 'もんじゃ', 'お好み焼き', '鉄板焼き']}\n",
      "----------\n",
      "./images/ja/pexels-photo-8366393.jpeg\n",
      "SceneXplain: \t{'text_strings': ['のれ', '味', '日']}\n",
      "OpenAI:\t\t{'text_strings': ['本日の日替わり']}\n",
      "----------\n",
      "./images/ar/pexels-photo-11127113.jpeg\n",
      "SceneXplain: \t{'text_strings': ['كذب الرجال', 'ولومر قوا ..']}\n",
      "OpenAI:\t\t{'text_strings': ['كريم أسامة', 'ترنيمة أيلول', 'في الحُب والحياة']}\n",
      "----------\n",
      "./images/ar/free-photo-of-signs-around-entrance-on-seashore.jpeg\n",
      "SceneXplain: \t{'text_strings': ['lucky', 'الشرح كدانوالصَّامياة', 'love']}\n",
      "OpenAI:\t\t{'text_strings': ['على بابك', 'انتظار', 'حظ', 'حلم', 'أمل', 'صبر', 'توكل', 'سعادة', 'حب']}\n",
      "----------\n",
      "./images/ar/pexels-photo-14900332.jpeg\n",
      "SceneXplain: \t{'text_strings': ['Capresse', 'Macchiato']}\n",
      "OpenAI:\t\t{'text_strings': ['جب زمین پر برف کی سفید چادر', 'تن دیتی ہے، تو ہم بھی برف بن جاتے ہیں،', 'لفظ اسپریسو']}\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for file, sx_record, oa_record in zip(image_files, scenex_response, openai_response):\n",
    "    print(file)\n",
    "    sx_answer = json.loads(sx_record['i18n']['en'])\n",
    "    oa_answer = json.loads(oa_record.message.content)\n",
    "\n",
    "    print(f\"SceneXplain: \\t{sx_answer}\")\n",
    "    print(f\"OpenAI:\\t\\t{oa_answer}\")\n",
    "    print(\"-\"*10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
