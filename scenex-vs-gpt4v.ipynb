{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d8c1f5-2dc8-4d8c-9b87-34a3850fc539",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "1. Put the images you want to process in `./images/`. This is already prepopulated with several images organized by language\n",
    "2. Run the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1386df22-9315-4e26-9689-62f98fa8dcc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'scenex-tests'...\n",
      "remote: Enumerating objects: 68, done.\u001b[K\n",
      "remote: Counting objects: 100% (68/68), done.\u001b[K\n",
      "remote: Compressing objects: 100% (56/56), done.\u001b[K\n",
      "remote: Total 68 (delta 21), reused 59 (delta 12), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (68/68), 5.51 MiB | 11.81 MiB/s, done.\n",
      "Resolving deltas: 100% (21/21), done.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "!rm -rf scenex-tests\n",
    "!git clone https://github.com/alexcg1/scenex-tests\n",
    "\n",
    "if os.getcwd() != 'scenex-tests':\n",
    "    os.chdir('scenex-tests')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be48c872-4acb-4b07-868d-c8cb408aa7b1",
   "metadata": {},
   "source": [
    "### Load API keys\n",
    "\n",
    "If you have `dotenv` installed and a `.env` file, the below code will load it from there. Otherwise you'll need to set `SCENEX_SECRET` and `OPENAI_API_KEY` environment variables manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e8af7257-3d0b-4dde-a39b-f2909b164cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded from .env\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    print(\"Environment variables loaded from .env\")\n",
    "except ImportError:\n",
    "    os.environ['OPENAI_API_KEY'] = \"<your OpenAI key>\"\n",
    "    os.environ['SCENEX_SECRET'] = \"<your SceneXplain key>\"\n",
    "    # print(\"Please set OPENAI_API_KEY and SCENEX_SECRET environment variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ffb26e-09e9-418a-850f-556e3616c449",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Pre-process images\n",
    "\n",
    "Convert all `webp` files to `jpeg`\n",
    "\n",
    "**Note:** No need to do this for existing images in repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f2ae4228-e64d-456f-a8e8-2f0db4f0c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ./images -type f -name \"*.webp\" -exec mogrify -format jpeg {} \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690a5191-761c-470c-8400-ae356a64a8ad",
   "metadata": {},
   "source": [
    "## Generate image list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "1c4c1c5d-b46d-4e93-a7f4-c9669820dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "filetypes = ['jpg', 'jpeg', 'png']\n",
    "file_path = './images/**/'\n",
    "image_files = []\n",
    "\n",
    "for filetype in filetypes:\n",
    "    image_files.extend(glob(f'{file_path}*.{filetype}'))\n",
    "\n",
    "# jpegs = glob('./images/**/*.jpeg')\n",
    "# jpegs = glob('./images/**/*.jpeg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "79c8736e-f596-4c77-8cce-7ab3e02e87f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./images/ar/artworks-000043896167-z3x71u-t500x500.jpg',\n",
       " './images/ar/ad_34496406_ce0f9beaaf3797bf_web.jpg',\n",
       " './images/ar/0a6b502ffc7c748cc918cbb80d73f960.jpg',\n",
       " './images/ar/create-arabic-food-poster-banner-or-social-media-ads.jpg',\n",
       " './images/ar/d46l5mu-22863ee5-ff85-4f18-ac95-2a76e16e9f77.jpg',\n",
       " './images/ko/pexels-photo-5051602.jpeg',\n",
       " './images/ko/pexels-photo-6314649.jpeg',\n",
       " './images/cn/pexels-photo-704379.jpeg',\n",
       " './images/cn/pexels-photo-5765624.jpeg',\n",
       " './images/cn/pexels-photo-2670327.jpeg',\n",
       " './images/cn/pexels-photo-2599543.jpeg',\n",
       " './images/cn/pexels-photo-3603453.jpeg',\n",
       " './images/ja/free-photo-of-prohibition-sign-in-japanese.jpeg',\n",
       " './images/ja/free-photo-of-illuminated-lantern-in-the-street.jpeg',\n",
       " './images/ja/pexels-photo-8366393.jpeg',\n",
       " './images/ar/pexels-photo-11127113.jpeg',\n",
       " './images/ar/free-photo-of-signs-around-entrance-on-seashore.jpeg']"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67282c3-31bb-4956-bb88-5a13ba090246",
   "metadata": {},
   "source": [
    "## Define functions for SceneXplain and OpenAI I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "dbf66d9f-587d-4d48-ba45-89e204f1999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import json\n",
    "import base64\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa1ee1-1179-4d8e-976b-3fbe003b2f23",
   "metadata": {},
   "source": [
    "#### SceneXplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "cba9391b-6024-4f70-8fd2-088f49f47549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SceneX setup and functions\n",
    "\n",
    "SCENEX_SECRET=os.getenv('SCENEX_SECRET')\n",
    "\n",
    "scenex_headers = {\n",
    "    \"x-api-key\": f\"token {SCENEX_SECRET}\",\n",
    "    \"content-type\": \"application/json\",\n",
    "}\n",
    "\n",
    "ALGO = \"Jelly\"\n",
    "\n",
    "def image_to_data_uri(file_path):\n",
    "    with open(file_path, \"rb\") as image_file:\n",
    "        encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "        return f\"data:image/png;base64,{encoded_image}\"\n",
    "        \n",
    "def generate_scenex_data(image_files, json_schema=None, question=None, features=[]):\n",
    "    data = {}\n",
    "    data['data'] = []\n",
    "\n",
    "    for file in image_files:\n",
    "        cid = file.split('/')[-1]\n",
    "        row = {\n",
    "            \"image\": image_to_data_uri(file),\n",
    "            \"features\": features,\n",
    "            \"algorithm\": ALGO,\n",
    "            \"cid\": cid\n",
    "        }\n",
    "\n",
    "        if question:\n",
    "            row[\"question\"] = question\n",
    "\n",
    "        if json_schema:\n",
    "            row[\"json_schema\"] = json_schema\n",
    "\n",
    "        data['data'].append(row)\n",
    "\n",
    "    return data\n",
    "\n",
    "def process_scenex(data):\n",
    "    connection = http.client.HTTPSConnection(\"api.scenex.jina.ai\")\n",
    "    connection.request(\"POST\", \"/v1/describe\", json.dumps(data), scenex_headers)\n",
    "    response = connection.getresponse()\n",
    "    response_data = response.read().decode(\"utf-8\")\n",
    "    \n",
    "    connection.close()\n",
    "\n",
    "    return json.loads(response_data)['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b3dfc0-f77b-4d76-b056-b4d5fe71da3e",
   "metadata": {},
   "source": [
    "#### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "6e0252a3-bede-4d54-9b56-30bd84582498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages (1.1.1)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages (from openai) (1.8.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages (from openai) (0.25.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages (from openai) (2.4.2)\n",
      "Requirement already satisfied: tqdm>4 in /mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages (from openai) (4.8.0)\n",
      "Requirement already satisfied: idna>=2.8 in /mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
      "Requirement already satisfied: certifi in /mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
      "Requirement already satisfied: httpcore in /mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai) (1.0.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.10.1 in /mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai) (2.10.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "c8088723-5c21-4f2c-af01-765348c13823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI functions\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def encode_openai_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def generate_openai_data(image_files, text=\"\"):\n",
    "    output = []\n",
    "    \n",
    "    for file in image_files:\n",
    "        base64_image = f\"data:image/jpeg;base64,{encode_openai_image(file)}\"\n",
    "        data = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                # \"filename\": file,\n",
    "                 \"content\": [\n",
    "                    {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": base64_image\n",
    "                    },\n",
    "                    {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": text\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        output.extend(data)\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "def process_openai(data):\n",
    "    output = []\n",
    "\n",
    "    for record in data:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-vision-preview\",\n",
    "            messages=[record],\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "\n",
    "        output.append(response.choices[0])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef2f7e3-42cb-46c9-9ade-b88e544685ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Basic captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb46c8-dbaa-480e-bb9b-e5dbc8453cb0",
   "metadata": {},
   "source": [
    "### SceneXplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabfedcd-8df9-4b4e-b392-da43c703e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_data = generate_scenex_data(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103b2820-2393-448c-9247-84b7af67d2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response = process_scenex(scenex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599146aa-57cb-419f-8afc-e718ca6d248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869556e5-10db-4c65-bd0b-516e85863866",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb5faa4-5753-4628-a41d-b60faf7442e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_data = generate_openai_data(image_files, \"what is in this image?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286be171-bdf7-4e5c-b16f-695109bea6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response = process_openai(openai_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d5d20-981d-4c01-8887-7d68837b6f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df646e-0784-4d59-8705-63e29329a975",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Visual question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba35725b-f587-4222-9e48-a461fc11da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'what does the text say in this image?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7885bd69-b20b-4a91-ac64-519995141843",
   "metadata": {},
   "source": [
    "### SceneXplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef268f-1fc6-4dd3-a277-92310569ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['question_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae18ec38-cc56-46b2-9bd8-ad31363601e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_data = generate_scenex_data(image_files, question=question, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c34f9b-c7c3-4608-96ad-0fa6e0090456",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response = process_scenex(scenex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99537e4d-ae3d-4cd6-95c8-eb8cb97db335",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed72dd62-d4d1-4be4-8001-b92459a78ce6",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe5cf36-87f8-45f1-8cd2-1c1d2549e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_data = generate_openai_data(image_files, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dccc86-b93a-4ad8-bb84-4ae037dd1c8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "openai_response = process_openai(openai_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0791a6ef-f2aa-431d-9da9-fbb9d531b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4337351-0307-4388-a5f0-a13d76c4f47b",
   "metadata": {},
   "source": [
    "## Extract JSON from image\n",
    "\n",
    "We'll use SceneXplain's \"Extract JSON from Image\" feature to extract each text string and output to JSON that fits a strict schema.\n",
    "\n",
    "We'll also try a klugy way to do this with OpenAI, in the interests of fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "021121c2-9f5a-425f-b57a-868ed9fc96fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = {\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"text_strings\": {\n",
    "      \"type\": \"array\",\n",
    "      \"description\": \"Every text string contained in the image. Consider all languages\"\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378ef9a-336f-41b4-8e74-caa63df82f10",
   "metadata": {},
   "source": [
    "### SceneX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5e4cc3fa-0792-4ba4-96c2-e287fb7c790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"json\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "78393558-5a7e-44ed-9c01-e271263a034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_data = generate_scenex_data(image_files, json_schema=json.dumps(json_schema), features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "36f45bf1-5b39-43f1-9afb-3899daf22783",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response = process_scenex(scenex_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0aff10-0363-438f-96ee-4848b99194ff",
   "metadata": {},
   "source": [
    "### OpenAI\n",
    "\n",
    "We have to kluge it a bit by asking for JSON output as part of the question. This may not always provide reliably strict output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "d2b62a39-0649-4fa9-bf34-40fe4b2a039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = f\"Extract the text strings from this image and populate a JSON that follows this schema:\\n\\n{str(json_schema)}. Return just the output JSON. Do not put it in a code block\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "057fe81a-cfd1-484a-babe-64bfbad4a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_data = generate_openai_data(image_files, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "6cc46cfe-c570-4f60-80e4-f4a60d32cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response = process_openai(openai_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baecfc6c-3513-4421-ae67-e5a0777aaba8",
   "metadata": {},
   "source": [
    "### Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "d924534b-185f-4c5b-9a1a-4763d4f39651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images/ko/pexels-photo-5051602.jpeg\n",
      "SceneXplain: \t{'text_strings': ['삼부식육점', '号号 号, 番号 7▲ 1.244-3800', '15']}\n",
      "OpenAI:\t\t{'text_strings': ['삼부', '전구', '디오', '문구', '생활용품', '금구', '도매', '1244-3800']}\n",
      "----------\n",
      "./images/ko/pexels-photo-6314649.jpeg\n",
      "SceneXplain: \t{'text_strings': ['|야', '좋은 날에 만나', '단이 방', '50', '좋은 나를 만나']}\n",
      "OpenAI:\t\t{'text_strings': ['삶은 날에 만나', '삶은 나를 만나', '닷이 발다']}\n",
      "----------\n",
      "./images/cn/pexels-photo-704379.jpeg\n",
      "SceneXplain: \t{'text_strings': ['饒河街觀光夜市', 'Raohe St. Night Market', '歡', '光', '健', '媽祖廟口', '服務台', '金瑞刊', '康']}\n",
      "OpenAI:\t\t{'text_strings': ['饒河街觀光夜市', 'Raohe St. Night Market', 'GOOD', '綜合果汁', '招牌麵線', 'QQ', '臭豆腐']}\n",
      "----------\n",
      "./images/cn/pexels-photo-5765624.jpeg\n",
      "SceneXplain: \t{'text_strings': ['宇', '川']}\n",
      "OpenAI:\t\t{'text_strings': ['京都嵐山']}\n",
      "----------\n",
      "./images/cn/pexels-photo-2670327.jpeg\n",
      "SceneXplain: \t{'text_strings': ['金钱肚20元', '旺角牛筋腩20元', '旺角牛杂18元']}\n",
      "OpenAI:\t\t{'text_strings': ['魚丸湯', '20元', '貢丸', '20元', '丸仔湯', '18元']}\n",
      "----------\n",
      "./images/cn/pexels-photo-2599543.jpeg\n",
      "SceneXplain: \t{'text_strings': ['為人演說不取於相如如', '持讀誦為人演說其福勝', '此經乃至四句', '『無量阿僧祗世界七', '不生活相發菩提', '句法應不是', '阿熊多羅二', '言法相酱如', '是見如是信解']}\n",
      "OpenAI:\t\t{'text_strings': ['博爱之门深处的暗号', '此日又是罗家祭日', '今日天朗气清且晴又好', '兄弟群赴西域长安道上', '任凭那风吹雨打不误前行', '多谢路过相知之士加持', '出门前听闻杜牧诗句贴门口', '嘱咐无论如何来路', '莫将他语与讲真假', '因为我们只信赏善罚恶', '冥冥中自有旨意', '命中注定会相会', '又岂在朝朝暮暮']}\n",
      "----------\n",
      "./images/cn/pexels-photo-3603453.jpeg\n",
      "SceneXplain: \t{'text_strings': ['老门框卤煮店', '老门框廣為心明', '王', '1', '卤']}\n",
      "OpenAI:\t\t{'text_strings': ['老门框炸酱面', '牛肉', '炒肝', '面食', '小吃']}\n",
      "----------\n",
      "./images/ja/free-photo-of-prohibition-sign-in-japanese.jpeg\n",
      "SceneXplain: \t{'text_strings': ['No Smoking', '禁止吸烟', '路上喫煙禁止区域']}\n",
      "OpenAI:\t\t{'text_strings': ['ポイ捨てご遠慮ください', 'LITTERING', '禁煙', 'NO SMOKING']}\n",
      "----------\n",
      "./images/ja/free-photo-of-illuminated-lantern-in-the-street.jpeg\n",
      "SceneXplain: \t{'text_strings': ['キリンラカー', 'こてつ象', '美子専門店']}\n",
      "OpenAI:\t\t{'text_strings': ['串カツ田中', 'もんじゃ', 'お好み焼き', '鉄板焼き']}\n",
      "----------\n",
      "./images/ja/pexels-photo-8366393.jpeg\n",
      "SceneXplain: \t{'text_strings': ['のれ', '味', '日']}\n",
      "OpenAI:\t\t{'text_strings': ['本日の日替わり']}\n",
      "----------\n",
      "./images/ar/pexels-photo-11127113.jpeg\n",
      "SceneXplain: \t{'text_strings': ['كذب الرجال', 'ولومر قوا ..']}\n",
      "OpenAI:\t\t{'text_strings': ['كريم أسامة', 'ترنيمة أيلول', 'في الحُب والحياة']}\n",
      "----------\n",
      "./images/ar/free-photo-of-signs-around-entrance-on-seashore.jpeg\n",
      "SceneXplain: \t{'text_strings': ['lucky', 'الشرح كدانوالصَّامياة', 'love']}\n",
      "OpenAI:\t\t{'text_strings': ['على بابك', 'انتظار', 'حظ', 'حلم', 'أمل', 'صبر', 'توكل', 'سعادة', 'حب']}\n",
      "----------\n",
      "./images/ar/pexels-photo-14900332.jpeg\n",
      "SceneXplain: \t{'text_strings': ['Capresse', 'Macchiato']}\n",
      "OpenAI:\t\t{'text_strings': ['جب زمین پر برف کی سفید چادر', 'تن دیتی ہے، تو ہم بھی برف بن جاتے ہیں،', 'لفظ اسپریسو']}\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for file, sx_record, oa_record in zip(image_files, scenex_response, openai_response):\n",
    "    print(file)\n",
    "    sx_answer = json.loads(sx_record['i18n']['en'])\n",
    "    oa_answer = json.loads(oa_record.message.content)\n",
    "\n",
    "    print(f\"SceneXplain: \\t{sx_answer}\")\n",
    "    print(f\"OpenAI:\\t\\t{oa_answer}\")\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a476b-7c78-407e-a103-a199cbad5005",
   "metadata": {},
   "source": [
    "## Extract more complex JSON\n",
    "\n",
    "Now we'll extract:\n",
    "\n",
    "- A general description of the scene\n",
    "- All text objects. Each object will contain:\n",
    "    - The text string itself\n",
    "    - The (human-readable) language of the string\n",
    "    - The ISO 639-1 language code (e.g. `en-US`)\n",
    "    - An English translation of the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "e709ca09-0b32-4bd4-9697-015795c4a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = {\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"long_description\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"description of the image. Up to 20 words.\"\n",
    "    },\n",
    "    \"text_objects\": {\n",
    "      \"type\": \"array\",\n",
    "      \"items\": {\n",
    "        \"type\": \"object\",\n",
    "        \"description\": \"array of JSON objects representing every text string in the image\",\n",
    "        \"properties\": {\n",
    "          \"text_string\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"the text string\"\n",
    "          },\n",
    "          \"english_translation\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"the english translation of text string\"\n",
    "          },\n",
    "          \"language\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"the language of the text string\"\n",
    "          },\n",
    "          \"iso_code\": {\n",
    "            \"type\": \"string\",\n",
    "            \"description\": \"iso-639-1 code for the language of the string\"\n",
    "          }\n",
    "        }\n",
    "      }\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7927fddc-fbfa-4386-ac79-4a5a184dc2b7",
   "metadata": {},
   "source": [
    "### SceneX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "87e57983-a775-4733-a6d5-9ab711675bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_data = generate_scenex_data(image_files, json_schema=json.dumps(json_schema), features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "c7794f16-5cd8-4ee8-99ea-7884adba4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response = process_scenex(scenex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "e440fbf6-8f72-4f20-ba66-bd205cda31c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images/ar/artworks-000043896167-z3x71u-t500x500.jpg\n",
      "{'long_description': 'An advertisement for 4G LTE. Two men, one in western '\n",
      "                     'clothes and one in Omani clothing, engaging in a playful '\n",
      "                     'fight.',\n",
      " 'text_objects': [{'english_translation': 'Life became faster',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'الحياة صارت أكثر سرعة'},\n",
      "                  {'english_translation': 'EAG',\n",
      "                   'iso_code': 'Undefined',\n",
      "                   'language': 'Undefined',\n",
      "                   'text_string': 'EAG'},\n",
      "                  {'english_translation': 'LTE',\n",
      "                   'iso_code': 'Undefined',\n",
      "                   'language': 'Undefined',\n",
      "                   'text_string': 'LTE'}]}\n",
      "----------\n",
      "./images/ar/ad_34496406_ce0f9beaaf3797bf_web.jpg\n",
      "{'long_description': 'An image of an advertisement showing a woman under a '\n",
      "                     'clear blue sky advertising the product Kiri with Arabic '\n",
      "                     'text.',\n",
      " 'text_objects': [{'english_translation': '00',\n",
      "                   'iso_code': 'en',\n",
      "                   'language': 'English',\n",
      "                   'text_string': '00'},\n",
      "                  {'english_translation': 'kiri®',\n",
      "                   'iso_code': 'en',\n",
      "                   'language': 'English',\n",
      "                   'text_string': 'kiri®'},\n",
      "                  {'english_translation': 'Taste and wear us (tentative '\n",
      "                                          'translation)',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': '... إيذ وووب'},\n",
      "                  {'english_translation': 'In the mouth! (tentative '\n",
      "                                          'translation)',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'في الفم !'},\n",
      "                  {'english_translation': 'For me to use Kiri (tentative '\n",
      "                                          'translation)',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'لي يستبن كيري'}]}\n",
      "----------\n",
      "./images/ar/0a6b502ffc7c748cc918cbb80d73f960.jpg\n",
      "{'long_description': 'Two hands are shown, one holding an eaten, and an '\n",
      "                     'unopened Kit Kat candy bar, in an Arabic advertisement '\n",
      "                     'with a casual, indulgent atmosphere.',\n",
      " 'text_objects': [{'english_translation': 'Kit Kat',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'كيت كات'},\n",
      "                  {'english_translation': 'One Riyal',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'بريَالَ وَاحِدْ'},\n",
      "                  {'english_translation': 'KitKat',\n",
      "                   'iso_code': 'en',\n",
      "                   'language': 'English',\n",
      "                   'text_string': 'KitKat'},\n",
      "                  {'english_translation': '25gNET',\n",
      "                   'iso_code': 'en',\n",
      "                   'language': 'English',\n",
      "                   'text_string': '25gNET'},\n",
      "                  {'english_translation': 'WAFER FINGERS IN A',\n",
      "                   'iso_code': 'en',\n",
      "                   'language': 'English',\n",
      "                   'text_string': 'WAFER FINGERS IN A'},\n",
      "                  {'english_translation': 'KitKat',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'كيتكات'}]}\n",
      "----------\n",
      "./images/ar/create-arabic-food-poster-banner-or-social-media-ads.jpg\n",
      "{'long_description': 'Social media restaurant promotion on an orange '\n",
      "                     'background, exhibiting meat dishes with special offers '\n",
      "                     'and an order button.',\n",
      " 'text_objects': [{'english_translation': 'Poster design',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'تصميم بوستر'},\n",
      "                  {'english_translation': 'In Arabic',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'بالعربية'},\n",
      "                  {'english_translation': 'Facebook logo',\n",
      "                   'iso_code': 'en',\n",
      "                   'language': 'English',\n",
      "                   'text_string': 'f'},\n",
      "                  {'english_translation': 'Special Offer!',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'عرض خاص!'},\n",
      "                  {'english_translation': 'SUN Discount',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'خصم SUN'},\n",
      "                  {'english_translation': 'Order Now',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'أطلب الآن'},\n",
      "                  {'english_translation': 'LinkedIn logo',\n",
      "                   'iso_code': 'en',\n",
      "                   'language': 'English',\n",
      "                   'text_string': 'in'},\n",
      "                  {'english_translation': 'Twitter logo',\n",
      "                   'iso_code': 'en',\n",
      "                   'language': 'English',\n",
      "                   'text_string': 't'},\n",
      "                  {'english_translation': 'Q Logo',\n",
      "                   'iso_code': 'en',\n",
      "                   'language': 'English',\n",
      "                   'text_string': 'Q'}]}\n",
      "----------\n",
      "./images/ar/d46l5mu-22863ee5-ff85-4f18-ac95-2a76e16e9f77.jpg\n",
      "{'long_description': 'An advertisement for \"Matarouk\" coffee featuring a '\n",
      "                     'gold-colored coffee jar with a black handle. The jar is '\n",
      "                     'filled with coffee and the background is a warm '\n",
      "                     'yellow-orange color. The text in the image is written in '\n",
      "                     'Arabic.',\n",
      " 'text_objects': [{'english_translation': 'Matouk',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'معتوق'},\n",
      "                  {'english_translation': 'MAATOUK',\n",
      "                   'iso_code': 'en',\n",
      "                   'language': 'English',\n",
      "                   'text_string': 'MAATOUK'},\n",
      "                  {'english_translation': '1 9 6 0',\n",
      "                   'iso_code': 'en',\n",
      "                   'language': 'English',\n",
      "                   'text_string': '1 9 6 0'},\n",
      "                  {'english_translation': 'Arabic Coffee',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'قهوة عربية'},\n",
      "                  {'english_translation': 'According to the origins',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'حسب الأصول'},\n",
      "                  {'english_translation': 'Dark roast',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'تحميص غامق'},\n",
      "                  {'english_translation': '100% Arabica Ground Coffee',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'بن مطحون ١٠٠٪ أرابيكا'},\n",
      "                  {'english_translation': 'Authentic taste and easy to prepare',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'أصالة المذاق وسهولة التحضير'},\n",
      "                  {'english_translation': 'Arabs have always been famous over '\n",
      "                                          'time for preparing Arabic coffee in '\n",
      "                                          'their homes, which is one of the '\n",
      "                                          'symbols of generosity and '\n",
      "                                          'hospitality',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'لطالما اشتهر العرب عبر ماضي الزمان بتحضير '\n",
      "                                  'القهوة العربية في منازلهم، والتي تعد من أحد '\n",
      "                                  'رموز الكرم والضيافة'},\n",
      "                  {'english_translation': 'Arabic. From here, Matouk factories '\n",
      "                                          'started to offer Arabic coffee that '\n",
      "                                          'is easy to prepare, with a '\n",
      "                                          'distinctive smell and authentic '\n",
      "                                          'taste',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'العربية. من هنا انطلقت مصانع معتوق لتقديم '\n",
      "                                  'القهوة العربية السهلة التحضير ذات الرائحة '\n",
      "                                  'المميزة والطعم الأصيل'},\n",
      "                  {'english_translation': 'Matarouk 1960 Arabic coffee, Arabic '\n",
      "                                          'coffee according to the origins',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'القهوة العربية معتوق ١٩٦٠، قهوة عربية حسب '\n",
      "                                  'الأصول'}]}\n",
      "----------\n",
      "./images/ko/pexels-photo-5051602.jpeg\n",
      "{'long_description': 'A street scene in an Asian city, presumably Korea, '\n",
      "                     'featuring a yellow-bricked building, with two people '\n",
      "                     'seemingly asleep inside. The vicinity includes bicycles, '\n",
      "                     'a broom, a fire hydrant, and a possible mattress.',\n",
      " 'text_objects': [{'english_translation': 'Butcher shop',\n",
      "                   'iso_code': 'ko',\n",
      "                   'language': 'Korean',\n",
      "                   'text_string': '삼부식육점'},\n",
      "                  {'english_translation': 'Phone number: 7▲ 1.244-3800',\n",
      "                   'iso_code': 'ko',\n",
      "                   'language': 'Korean',\n",
      "                   'text_string': '号号 号, 番号 7▲ 1.244-3800'},\n",
      "                  {'english_translation': '15',\n",
      "                   'iso_code': 'unknown',\n",
      "                   'language': 'Unknown',\n",
      "                   'text_string': '15'}]}\n",
      "----------\n",
      "./images/ko/pexels-photo-6314649.jpeg\n",
      "{'long_description': 'A room with a wooden table surrounded by chairs, items '\n",
      "                     'on table, and a blue Korean neon sign.',\n",
      " 'text_objects': [{'english_translation': '|ya',\n",
      "                   'iso_code': 'ko',\n",
      "                   'language': 'Korean',\n",
      "                   'text_string': '|야'},\n",
      "                  {'english_translation': 'Meet on a good day',\n",
      "                   'iso_code': 'ko',\n",
      "                   'language': 'Korean',\n",
      "                   'text_string': '좋은 날에 만나'},\n",
      "                  {'english_translation': 'A honey room',\n",
      "                   'iso_code': 'ko',\n",
      "                   'language': 'Korean',\n",
      "                   'text_string': '단이 방'},\n",
      "                  {'english_translation': '50',\n",
      "                   'iso_code': 'en',\n",
      "                   'language': 'English',\n",
      "                   'text_string': '50'},\n",
      "                  {'english_translation': 'Meet a better me',\n",
      "                   'iso_code': 'ko',\n",
      "                   'language': 'Korean',\n",
      "                   'text_string': '좋은 나를 만나'}]}\n",
      "----------\n",
      "./images/cn/pexels-photo-704379.jpeg\n",
      "{'long_description': 'A vibrant, bustling Taiwanese night market, bathed under '\n",
      "                     'neon lights and filled with people browsing the scene.',\n",
      " 'text_objects': [{'english_translation': 'Raohe St. Night Market',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '饒河街觀光夜市'},\n",
      "                  {'english_translation': 'Raohe St. Night Market',\n",
      "                   'iso_code': 'en',\n",
      "                   'language': 'English',\n",
      "                   'text_string': 'Raohe St. Night Market'},\n",
      "                  {'english_translation': 'Welcome',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '歡'},\n",
      "                  {'english_translation': 'Light',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '光'},\n",
      "                  {'english_translation': 'Healthy',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '健'},\n",
      "                  {'english_translation': 'Entrance to Mazu Temple',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '媽祖廟口'},\n",
      "                  {'english_translation': 'Service Desk',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '服務台'},\n",
      "                  {'english_translation': 'Jinrui Publication',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '金瑞刊'},\n",
      "                  {'english_translation': 'Health',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '康'}]}\n",
      "----------\n",
      "./images/cn/pexels-photo-5765624.jpeg\n",
      "{'long_description': 'A close-up shot of a weathered granite stone with the '\n",
      "                     \"Chinese characters '宇田川常' engraved onto it.\",\n",
      " 'text_objects': [{'english_translation': \"The English translation wasn't \"\n",
      "                                          'feasible due to limited context '\n",
      "                                          'information.',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '宇田川常'}]}\n",
      "----------\n",
      "./images/cn/pexels-photo-2670327.jpeg\n",
      "{'long_description': 'An image of a man in a bustling Asian food market '\n",
      "                     'preparing food at a stall, displaying two signs with the '\n",
      "                     'prices of their dishes.',\n",
      " 'text_objects': [{'english_translation': 'Tripe, 20 yuan',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '金钱肚20元'},\n",
      "                  {'english_translation': 'Mongkok beef tendon and brisket, 20 '\n",
      "                                          'yuan',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '旺角牛筋腩20元'},\n",
      "                  {'english_translation': 'Mongkok beef offal, 18 yuan',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '旺角牛杂18元'}]}\n",
      "----------\n",
      "./images/cn/pexels-photo-2599543.jpeg\n",
      "{'long_description': 'The image shows a large wall with Chinese characters '\n",
      "                     'carved into it from rows bottom to top, making an '\n",
      "                     'impressive sight in a traditional and solemn setting.',\n",
      " 'text_objects': [{'english_translation': '[Translated to English]',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '為人演說不取於相如如'},\n",
      "                  {'english_translation': '[Translated to English]',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '持讀誦為人演說其福勝'},\n",
      "                  {'english_translation': '[Translated to English]',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '此經乃至四句'},\n",
      "                  {'english_translation': '[Translated to English]',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '『無量阿僧祗世界七'},\n",
      "                  {'english_translation': '[Translated to English]',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '不生活相發菩提'},\n",
      "                  {'english_translation': '[Translated to English]',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '句法應不是'},\n",
      "                  {'english_translation': '[Translated to English]',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '阿熊多羅二'},\n",
      "                  {'english_translation': '[Translated to English]',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '言法相酱如'},\n",
      "                  {'english_translation': '[Translated to English]',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '是見如是信解'}]}\n",
      "----------\n",
      "./images/cn/pexels-photo-3603453.jpeg\n",
      "{'long_description': 'Asian chef is cooking in a restaurant kitchen viewed '\n",
      "                     'through a glass window, with Chinese name of the place '\n",
      "                     'displayed.',\n",
      " 'text_objects': [{'english_translation': 'None (Requires proper translation)',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '老门框廣為心明'},\n",
      "                  {'english_translation': 'King',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '王'},\n",
      "                  {'english_translation': '1',\n",
      "                   'iso_code': 'None',\n",
      "                   'language': 'Not applicable',\n",
      "                   'text_string': '1'},\n",
      "                  {'english_translation': 'Braised / Marinated',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '卤'}]}\n",
      "----------\n",
      "./images/ja/free-photo-of-prohibition-sign-in-japanese.jpeg\n",
      "{'long_description': \"The image represents a rectangular 'no smoking' sign \"\n",
      "                     'posted on a grey marble surface, written in multiple '\n",
      "                     'languages.',\n",
      " 'text_objects': [{'english_translation': 'No Smoking Area on the Road',\n",
      "                   'iso_code': 'zh',\n",
      "                   'language': 'Chinese',\n",
      "                   'text_string': '路上喫煙禁止区域'}]}\n",
      "----------\n",
      "./images/ja/free-photo-of-illuminated-lantern-in-the-street.jpeg\n",
      "{'long_description': 'Nighttime scene of an Asian market lit by various '\n",
      "                     'lanterns with Japanese writing.',\n",
      " 'text_objects': [{'english_translation': '',\n",
      "                   'iso_code': 'ja',\n",
      "                   'language': 'Japanese',\n",
      "                   'text_string': 'キリンラカー'},\n",
      "                  {'english_translation': '',\n",
      "                   'iso_code': 'ja',\n",
      "                   'language': 'Japanese',\n",
      "                   'text_string': 'こてつ象'},\n",
      "                  {'english_translation': '',\n",
      "                   'iso_code': 'ja',\n",
      "                   'language': 'Japanese',\n",
      "                   'text_string': '美子専門店'}]}\n",
      "----------\n",
      "./images/ja/pexels-photo-8366393.jpeg\n",
      "{'long_description': 'A red and blue neon sign displaying a phrase in Japanese '\n",
      "                     'about the taste or flavor of the day, located in a dim '\n",
      "                     'or dark setting.',\n",
      " 'text_objects': [{'english_translation': 'Translation not available',\n",
      "                   'iso_code': 'ja',\n",
      "                   'language': 'Japanese',\n",
      "                   'text_string': 'のれ'},\n",
      "                  {'english_translation': 'Translation not available',\n",
      "                   'iso_code': 'ja',\n",
      "                   'language': 'Japanese',\n",
      "                   'text_string': '味'},\n",
      "                  {'english_translation': 'Translation not available',\n",
      "                   'iso_code': 'ja',\n",
      "                   'language': 'Japanese',\n",
      "                   'text_string': '日'}]}\n",
      "----------\n",
      "./images/ar/pexels-photo-11127113.jpeg\n",
      "{'long_description': 'A person in a hijab and light blue top, reading an '\n",
      "                     'Arabic book against a light blue background, with a '\n",
      "                     'focus on their hands.',\n",
      " 'text_objects': [{'english_translation': '',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'كذب الرجال'},\n",
      "                  {'english_translation': '',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'ولومر قوا'}]}\n",
      "----------\n",
      "./images/ar/free-photo-of-signs-around-entrance-on-seashore.jpeg\n",
      "{'long_description': 'A wooden gate with Arabic writing on a beach leading to '\n",
      "                     'a chair and table with the sea as backdrop.',\n",
      " 'text_objects': [{'english_translation': '',\n",
      "                   'iso_code': 'en',\n",
      "                   'language': 'English',\n",
      "                   'text_string': 'Lucky'},\n",
      "                  {'english_translation': '',\n",
      "                   'iso_code': 'ar',\n",
      "                   'language': 'Arabic',\n",
      "                   'text_string': 'الشرح كدانوالصَّامياة'},\n",
      "                  {'english_translation': '',\n",
      "                   'iso_code': 'en',\n",
      "                   'language': 'English',\n",
      "                   'text_string': 'love'}]}\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for file, sx_record in zip(image_files, scenex_response):\n",
    "    print(file)\n",
    "    try:\n",
    "        sx_answer = json.loads(sx_record['i18n']['en'])\n",
    "\n",
    "        \n",
    "        pprint(sx_answer)\n",
    "        print(\"-\"*10)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc359a40-3721-4408-a327-c0b74411e80f",
   "metadata": {},
   "source": [
    "### OpenAI\n",
    "\n",
    "We have to kluge it a bit by asking for JSON output as part of the question. This may not always provide reliably strict output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "a04ddc63-1ae0-4c81-bdd7-c7d6d57bd67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = f\"Extract the text strings from this image and populate a JSON that follows this schema:\\n\\n{str(json_schema)}. Return just the output JSON. Do not put it in a code block\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "63639668-87c2-43e3-860a-bd57d9f1f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_data = generate_openai_data(image_files, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "48007907-4859-4c05-a215-eda31a941eca",
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalServerError",
     "evalue": "Error code: 503 - {'error': {'code': 503, 'message': 'Service Unavailable.', 'param': None, 'type': 'cf_service_unavailable'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[106], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m openai_response \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_openai\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopenai_data\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[81], line 58\u001b[0m, in \u001b[0;36mprocess_openai\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     55\u001b[0m output \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m record \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m---> 58\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgpt-4-vision-preview\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mrecord\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     output\u001b[38;5;241m.\u001b[39mappend(response\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m/mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages/openai/_utils/_utils.py:299\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    297\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    298\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages/openai/resources/chat/completions.py:556\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, max_tokens, n, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    554\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    555\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 556\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    557\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    558\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    559\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    560\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    561\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    562\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    563\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    564\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    565\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    566\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    567\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    568\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    569\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    570\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    571\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    572\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    573\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    574\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    575\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    579\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    587\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages/openai/_base_client.py:1055\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1042\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1043\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1050\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1051\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1052\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1053\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1054\u001b[0m     )\n\u001b[0;32m-> 1055\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m/mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages/openai/_base_client.py:834\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    826\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    827\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    832\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    833\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 834\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    837\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    839\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    840\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages/openai/_base_client.py:865\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m--> 865\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages/openai/_base_client.py:925\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m    923\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages/openai/_base_client.py:865\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m err:  \u001b[38;5;66;03m# thrown on 4xx and 5xx status code\u001b[39;00m\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_should_retry(err\u001b[38;5;241m.\u001b[39mresponse):\n\u001b[0;32m--> 865\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_retry_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m            \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    867\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    868\u001b[0m \u001b[43m            \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m            \u001b[49m\u001b[43merr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    872\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n",
      "File \u001b[0;32m/mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages/openai/_base_client.py:925\u001b[0m, in \u001b[0;36mSyncAPIClient._retry_request\u001b[0;34m(self, options, cast_to, remaining_retries, response_headers, stream, stream_cls)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;66;03m# In a synchronous context we are blocking the entire thread. Up to the library user to run the client in a\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;66;03m# different thread if necessary.\u001b[39;00m\n\u001b[1;32m    923\u001b[0m time\u001b[38;5;241m.\u001b[39msleep(timeout)\n\u001b[0;32m--> 925\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m    \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    929\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    930\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    931\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/data/work/blog/scenex/non-english/env/lib/python3.11/site-packages/openai/_base_client.py:877\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    874\u001b[0m     \u001b[38;5;66;03m# If the response is streamed then we need to explicitly read the response\u001b[39;00m\n\u001b[1;32m    875\u001b[0m     \u001b[38;5;66;03m# to completion before attempting to access the response text.\u001b[39;00m\n\u001b[1;32m    876\u001b[0m     err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[0;32m--> 877\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mTimeoutException \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m    879\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m retries \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[0;31mInternalServerError\u001b[0m: Error code: 503 - {'error': {'code': 503, 'message': 'Service Unavailable.', 'param': None, 'type': 'cf_service_unavailable'}}"
     ]
    }
   ],
   "source": [
    "openai_response = process_openai(openai_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e2a19b-00da-4ef6-b400-b3be3957ac0b",
   "metadata": {},
   "source": [
    "### Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "32180368-2f3a-4662-93ee-9d6b108560c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images/ko/pexels-photo-5051602.jpeg\n",
      "SceneXplain: \t{'text_strings': ['삼부식육점', '号号 号, 番号 7▲ 1.244-3800', '15']}\n",
      "OpenAI:\t\t{'text_strings': ['삼부', '전구', '디오', '문구', '생활용품', '금구', '도매', '1244-3800']}\n",
      "----------\n",
      "./images/ko/pexels-photo-6314649.jpeg\n",
      "SceneXplain: \t{'text_strings': ['|야', '좋은 날에 만나', '단이 방', '50', '좋은 나를 만나']}\n",
      "OpenAI:\t\t{'text_strings': ['삶은 날에 만나', '삶은 나를 만나', '닷이 발다']}\n",
      "----------\n",
      "./images/cn/pexels-photo-704379.jpeg\n",
      "SceneXplain: \t{'text_strings': ['饒河街觀光夜市', 'Raohe St. Night Market', '歡', '光', '健', '媽祖廟口', '服務台', '金瑞刊', '康']}\n",
      "OpenAI:\t\t{'text_strings': ['饒河街觀光夜市', 'Raohe St. Night Market', 'GOOD', '綜合果汁', '招牌麵線', 'QQ', '臭豆腐']}\n",
      "----------\n",
      "./images/cn/pexels-photo-5765624.jpeg\n",
      "SceneXplain: \t{'text_strings': ['宇', '川']}\n",
      "OpenAI:\t\t{'text_strings': ['京都嵐山']}\n",
      "----------\n",
      "./images/cn/pexels-photo-2670327.jpeg\n",
      "SceneXplain: \t{'text_strings': ['金钱肚20元', '旺角牛筋腩20元', '旺角牛杂18元']}\n",
      "OpenAI:\t\t{'text_strings': ['魚丸湯', '20元', '貢丸', '20元', '丸仔湯', '18元']}\n",
      "----------\n",
      "./images/cn/pexels-photo-2599543.jpeg\n",
      "SceneXplain: \t{'text_strings': ['為人演說不取於相如如', '持讀誦為人演說其福勝', '此經乃至四句', '『無量阿僧祗世界七', '不生活相發菩提', '句法應不是', '阿熊多羅二', '言法相酱如', '是見如是信解']}\n",
      "OpenAI:\t\t{'text_strings': ['博爱之门深处的暗号', '此日又是罗家祭日', '今日天朗气清且晴又好', '兄弟群赴西域长安道上', '任凭那风吹雨打不误前行', '多谢路过相知之士加持', '出门前听闻杜牧诗句贴门口', '嘱咐无论如何来路', '莫将他语与讲真假', '因为我们只信赏善罚恶', '冥冥中自有旨意', '命中注定会相会', '又岂在朝朝暮暮']}\n",
      "----------\n",
      "./images/cn/pexels-photo-3603453.jpeg\n",
      "SceneXplain: \t{'text_strings': ['老门框卤煮店', '老门框廣為心明', '王', '1', '卤']}\n",
      "OpenAI:\t\t{'text_strings': ['老门框炸酱面', '牛肉', '炒肝', '面食', '小吃']}\n",
      "----------\n",
      "./images/ja/free-photo-of-prohibition-sign-in-japanese.jpeg\n",
      "SceneXplain: \t{'text_strings': ['No Smoking', '禁止吸烟', '路上喫煙禁止区域']}\n",
      "OpenAI:\t\t{'text_strings': ['ポイ捨てご遠慮ください', 'LITTERING', '禁煙', 'NO SMOKING']}\n",
      "----------\n",
      "./images/ja/free-photo-of-illuminated-lantern-in-the-street.jpeg\n",
      "SceneXplain: \t{'text_strings': ['キリンラカー', 'こてつ象', '美子専門店']}\n",
      "OpenAI:\t\t{'text_strings': ['串カツ田中', 'もんじゃ', 'お好み焼き', '鉄板焼き']}\n",
      "----------\n",
      "./images/ja/pexels-photo-8366393.jpeg\n",
      "SceneXplain: \t{'text_strings': ['のれ', '味', '日']}\n",
      "OpenAI:\t\t{'text_strings': ['本日の日替わり']}\n",
      "----------\n",
      "./images/ar/pexels-photo-11127113.jpeg\n",
      "SceneXplain: \t{'text_strings': ['كذب الرجال', 'ولومر قوا ..']}\n",
      "OpenAI:\t\t{'text_strings': ['كريم أسامة', 'ترنيمة أيلول', 'في الحُب والحياة']}\n",
      "----------\n",
      "./images/ar/free-photo-of-signs-around-entrance-on-seashore.jpeg\n",
      "SceneXplain: \t{'text_strings': ['lucky', 'الشرح كدانوالصَّامياة', 'love']}\n",
      "OpenAI:\t\t{'text_strings': ['على بابك', 'انتظار', 'حظ', 'حلم', 'أمل', 'صبر', 'توكل', 'سعادة', 'حب']}\n",
      "----------\n",
      "./images/ar/pexels-photo-14900332.jpeg\n",
      "SceneXplain: \t{'text_strings': ['Capresse', 'Macchiato']}\n",
      "OpenAI:\t\t{'text_strings': ['جب زمین پر برف کی سفید چادر', 'تن دیتی ہے، تو ہم بھی برف بن جاتے ہیں،', 'لفظ اسپریسو']}\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for file, sx_record, oa_record in zip(image_files, scenex_response, openai_response):\n",
    "    print(file)\n",
    "    sx_answer = json.loads(sx_record['i18n']['en'])\n",
    "    oa_answer = json.loads(oa_record.message.content)\n",
    "\n",
    "    print(f\"SceneXplain: \\t{sx_answer}\")\n",
    "    print(f\"OpenAI:\\t\\t{oa_answer}\")\n",
    "    print(\"-\"*10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
