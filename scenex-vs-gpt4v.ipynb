{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d8c1f5-2dc8-4d8c-9b87-34a3850fc539",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "1. Put the images you want to process in `./images/`. This is already prepopulated with several images organized by language\n",
    "2. Run the notebook\n",
    "\n",
    "### On Colab?\n",
    "\n",
    "Run the cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1386df22-9315-4e26-9689-62f98fa8dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "!git clone https://github.com/alexcg1/scenex-tests\n",
    "!os.chdir('scenex-tests')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be48c872-4acb-4b07-868d-c8cb408aa7b1",
   "metadata": {},
   "source": [
    "### Load API keys\n",
    "\n",
    "If you have `dotenv` installed and a `.env` file, the below code will load it from there. Otherwise you'll need to set `SCENEX_SECRET` and `OPENAI_API_KEY` environment variables manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e8af7257-3d0b-4dde-a39b-f2909b164cbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment variables loaded from .env\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    print(\"Environment variables loaded from .env\")\n",
    "except ImportError:\n",
    "    os.environ['OPENAI_API_KEY'] = \"<your OpenAI key>\"\n",
    "    os.environ['SCENEX_SECRET'] = \"<your SceneXplain key>\"\n",
    "    # print(\"Please set OPENAI_API_KEY and SCENEX_SECRET environment variables\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ffb26e-09e9-418a-850f-556e3616c449",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Pre-process images\n",
    "\n",
    "Convert all `webp` files to `jpeg`\n",
    "\n",
    "**Note:** No need to do this for existing images in repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ae4228-e64d-456f-a8e8-2f0db4f0c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !find ./images -type f -name \"*.webp\" -exec mogrify -format jpeg {} \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690a5191-761c-470c-8400-ae356a64a8ad",
   "metadata": {},
   "source": [
    "## Generate image list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d1c3af46-0542-4cde-a521-9e83bb032dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_COUNT = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1c4c1c5d-b46d-4e93-a7f4-c9669820dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "image_files = glob('./images/**/*.jpeg')[:MAX_COUNT]  # just test a few for now"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67282c3-31bb-4956-bb88-5a13ba090246",
   "metadata": {},
   "source": [
    "## Define functions for SceneXplain and OpenAI I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dbf66d9f-587d-4d48-ba45-89e204f1999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import json\n",
    "import base64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cba9391b-6024-4f70-8fd2-088f49f47549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SceneX setup and functions\n",
    "\n",
    "SCENEX_SECRET=os.getenv('SCENEX_SECRET')\n",
    "\n",
    "scenex_headers = {\n",
    "    \"x-api-key\": f\"token {SCENEX_SECRET}\",\n",
    "    \"content-type\": \"application/json\",\n",
    "}\n",
    "\n",
    "ALGO = \"Jelly\"\n",
    "\n",
    "def image_to_data_uri(file_path):\n",
    "    with open(file_path, \"rb\") as image_file:\n",
    "        encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "        return f\"data:image/png;base64,{encoded_image}\"\n",
    "        \n",
    "def generate_scenex_data(image_files, json_schema=None, question=None, features=[]):\n",
    "    data = {}\n",
    "    data['data'] = []\n",
    "\n",
    "    for file in image_files:\n",
    "        cid = file.split('/')[-1]\n",
    "        row = {\n",
    "            \"image\": image_to_data_uri(file),\n",
    "            \"features\": features,\n",
    "            \"algorithm\": ALGO,\n",
    "            \"cid\": cid\n",
    "        }\n",
    "\n",
    "        if question:\n",
    "            row[\"question\"] = question\n",
    "\n",
    "        if json_schema:\n",
    "            row[\"json_schema\"] = json_schema\n",
    "\n",
    "        data['data'].append(row)\n",
    "\n",
    "    return data\n",
    "\n",
    "def process_scenex(data):\n",
    "    connection = http.client.HTTPSConnection(\"api.scenex.jina.ai\")\n",
    "    connection.request(\"POST\", \"/v1/describe\", json.dumps(data), scenex_headers)\n",
    "    response = connection.getresponse()\n",
    "    response_data = response.read().decode(\"utf-8\")\n",
    "    \n",
    "    connection.close()\n",
    "\n",
    "    return json.loads(response_data)['result']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c8088723-5c21-4f2c-af01-765348c13823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI functions\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def encode_openai_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def generate_openai_data(image_files, text=\"\"):\n",
    "    output = []\n",
    "    # messages = [{\"role\": \"user\",\"content\": []}]\n",
    "    \n",
    "    for file in image_files:\n",
    "        base64_image = f\"data:image/jpeg;base64,{encode_openai_image(file)}\"\n",
    "        data = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                # \"filename\": file,\n",
    "                 \"content\": [\n",
    "                    {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": base64_image\n",
    "                    },\n",
    "                    {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": text\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        output.extend(data)\n",
    "        \n",
    "    return output\n",
    "\n",
    "# def process_openai(data):\n",
    "#     output = []\n",
    "    \n",
    "#     for record in data:\n",
    "#         print(record['role'])\n",
    "#         print(\"---\")\n",
    "#         response = client.chat.completions.create(\n",
    "#             model=\"gpt-4-vision-preview\",\n",
    "#             messages=messages,\n",
    "#             max_tokens=1000,\n",
    "#         )\n",
    "    \n",
    "#         output.append(response.choices[0])\n",
    "\n",
    "#     return output\n",
    "\n",
    "def process_openai(data):\n",
    "    # print(len(data))\n",
    "    output = []\n",
    "\n",
    "    for record in data:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-vision-preview\",\n",
    "            messages=data,\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "\n",
    "        output.append(response.choices[0])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef2f7e3-42cb-46c9-9ade-b88e544685ed",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Basic captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb46c8-dbaa-480e-bb9b-e5dbc8453cb0",
   "metadata": {},
   "source": [
    "### SceneXplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabfedcd-8df9-4b4e-b392-da43c703e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_data = generate_scenex_data(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103b2820-2393-448c-9247-84b7af67d2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response = process_scenex(scenex_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869556e5-10db-4c65-bd0b-516e85863866",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb5faa4-5753-4628-a41d-b60faf7442e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_data = generate_openai_data(image_files, \"what is in this image?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286be171-bdf7-4e5c-b16f-695109bea6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response = process_openai(openai_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d5d20-981d-4c01-8887-7d68837b6f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df646e-0784-4d59-8705-63e29329a975",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Visual question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba35725b-f587-4222-9e48-a461fc11da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'what does the text say in this image?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7885bd69-b20b-4a91-ac64-519995141843",
   "metadata": {},
   "source": [
    "### SceneXplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef268f-1fc6-4dd3-a277-92310569ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['question_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae18ec38-cc56-46b2-9bd8-ad31363601e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_data = generate_scenex_data(image_files, question=question, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c34f9b-c7c3-4608-96ad-0fa6e0090456",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response = process_scenex(scenex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99537e4d-ae3d-4cd6-95c8-eb8cb97db335",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed72dd62-d4d1-4be4-8001-b92459a78ce6",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe5cf36-87f8-45f1-8cd2-1c1d2549e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_data = generate_openai_data(image_files, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dccc86-b93a-4ad8-bb84-4ae037dd1c8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "openai_response = process_openai(openai_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0791a6ef-f2aa-431d-9da9-fbb9d531b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4337351-0307-4388-a5f0-a13d76c4f47b",
   "metadata": {},
   "source": [
    "## JSON Schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "021121c2-9f5a-425f-b57a-868ed9fc96fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = {\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"text_strings\": {\n",
    "      \"type\": \"array\",\n",
    "      \"description\": \"Every text string contained in the image. Consider all languages\"\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378ef9a-336f-41b4-8e74-caa63df82f10",
   "metadata": {},
   "source": [
    "### SceneX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5e4cc3fa-0792-4ba4-96c2-e287fb7c790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"json\", \"high_quality\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "78393558-5a7e-44ed-9c01-e271263a034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_data = generate_scenex_data(image_files, json_schema=json.dumps(json_schema), features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "36f45bf1-5b39-43f1-9afb-3899daf22783",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response = process_scenex(scenex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5327faa8-6a61-4720-880f-d4dd0b4e16bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images/ko/pexels-photo-5051602.jpeg\n",
      "SceneXplain: \t{'text_strings': ['성원어울', '삼부식육점', '号号 号, 番号 7▲ 1.244-3800', '15']}\n",
      "----------\n",
      "./images/ko/pexels-photo-6314649.jpeg\n",
      "SceneXplain: \t{'text_strings': ['|야', '좋은 날에 만나', '단이 방', '50', '좋은 나를 만나']}\n",
      "----------\n",
      "./images/cn/pexels-photo-704379.jpeg\n",
      "SceneXplain: \t{'text_strings': ['饒河街觀光夜市', 'Raohe St. Night Market', '歡', '光', '健', '媽祖廟口', '服務台', '金瑞刊', '康']}\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for file, sx_record in zip(image_files, scenex_response):\n",
    "    print(file)\n",
    "    sx_answer = json.loads(sx_record['i18n']['en'])\n",
    "\n",
    "    print(f\"SceneXplain: \\t{sx_answer}\")\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0aff10-0363-438f-96ee-4848b99194ff",
   "metadata": {},
   "source": [
    "### OpenAI\n",
    "\n",
    "We have to kluge it a bit by asking for JSON output as part of the question. This may not always provide reliably strict output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2b62a39-0649-4fa9-bf34-40fe4b2a039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = f\"Extract the text strings from this image and populate a JSON that follows this schema:\\n\\n{str(json_schema)}. Return just the output JSON. Do not put it in a code block\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "057fe81a-cfd1-484a-babe-64bfbad4a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_data = generate_openai_data(image_files, question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc71a7e2-8c70-45ba-a4ed-829ba81302ab",
   "metadata": {},
   "source": [
    "#### \\<debug\\>\n",
    "\n",
    "For some reason I get similar results for every image I sent to GPT-4V. This is me trying to debug why"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9857a02e-40c7-480c-9cb2-aa203cd2626a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check filenames are different\n",
    "# [row['filename'] for row in openai_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "61546bf3-7c91-471b-a6ed-8307173f38bb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# check that base64-encoded images aren't same\n",
    "assert openai_data[0]['content'][0]['image_url'] != openai_data[1]['content'][0]['image_url']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d8a6ea9-3a2a-4e0e-9443-3e37db8823a9",
   "metadata": {},
   "source": [
    "#### \\</debug\\>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6cc46cfe-c570-4f60-80e4-f4a60d32cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response = process_openai(openai_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "606363ea-e227-4b07-8d94-21ddd1aed6bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Choice(finish_reason=None, index=0, message=ChatCompletionMessage(content='{\\n  \"text_strings\": [\\n    \"饒河街觀光夜市\",\\n    \"Raohe St. Night Market\",\\n    \"皇冠\",\\n    \"大同\",\\n    \"老舅\",\\n    \"美而美\"\\n  ]\\n}', role='assistant', function_call=None, tool_calls=None), finish_details={'type': 'stop', 'stop': '<|fim_suffix|>'}),\n",
       " Choice(finish_reason=None, index=0, message=ChatCompletionMessage(content='{\\n  \"text_strings\": [\\n    \"饒河街觀光夜市\",\\n    \"Raohe St. Night Market\",\\n    \"良品\",\\n    \"招牌\",\\n    \"豚骨\",\\n    \"頂級\",\\n    \"滷味\",\\n    \"烤物\",\\n    \"海產\",\\n    \"金得春\"\\n  ]\\n}', role='assistant', function_call=None, tool_calls=None), finish_details={'type': 'stop', 'stop': '<|fim_suffix|>'}),\n",
       " Choice(finish_reason=None, index=0, message=ChatCompletionMessage(content='{\\n  \"text_strings\": [\\n    \"饒河街觀光夜市\",\\n    \"Raohe St. Night Market\",\\n    \"藥\",\\n    \"冰\",\\n    \"滷味\",\\n    \"鴨肉焿\"\\n  ]\\n}', role='assistant', function_call=None, tool_calls=None), finish_details={'type': 'stop', 'stop': '<|fim_suffix|>'})]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "openai_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baecfc6c-3513-4421-ae67-e5a0777aaba8",
   "metadata": {},
   "source": [
    "### Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d924534b-185f-4c5b-9a1a-4763d4f39651",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./images/ko/pexels-photo-5051602.jpeg\n",
      "SceneXplain: \t{'text_strings': ['삼부식육점', '号号 号, 番号 7▲ 1.244-3800', '15']}\n",
      "OpenAI:\t\t{'text_strings': ['جانا ہے تو جا، نہیں کوئی ہے تجھ سا', 'محبتوں کے سمندر میں', 'simple', 'coffee', 'Latte Espresso Cappuccino Americano Coffee']}\n",
      "----------\n",
      "./images/ko/pexels-photo-6314649.jpeg\n",
      "SceneXplain: \t{'text_strings': []}\n",
      "OpenAI:\t\t{'text_strings': ['جا میں ہوتی ہوں وہاں میں نہیں ہوتا', 'میں جہاں ہوں وہاں میں نہیں ہوتا', 'Latte Espresso Cappuccino Caffe Latte Americano']}\n",
      "----------\n",
      "./images/cn/pexels-photo-704379.jpeg\n",
      "SceneXplain: \t{'text_strings': ['Raohe St. Night Market', 'Chinese signs']}\n",
      "OpenAI:\t\t{'text_strings': ['جای خالی تو همچون جام می خالیست', 'بی تو هر آنچه دارم عین خسارت است', 'Latte Espresso Cappuccino']}\n",
      "----------\n",
      "./images/cn/pexels-photo-5765624.jpeg\n",
      "SceneXplain: \t{'text_strings': ['宇', '川']}\n",
      "OpenAI:\t\t{'text_strings': ['میری نہ چھوڑنے کا وعدہ کر', 'میں بھی وعدہ کروں گا بھول جانے کا', 'Latte Espresso Cappuccino Americano Coffee']}\n",
      "----------\n",
      "./images/cn/pexels-photo-2670327.jpeg\n",
      "SceneXplain: \t{'text_strings': ['金钱肚', '20元', '旺角牛筋腩', '20元', '旺角牛杂', '18元']}\n",
      "OpenAI:\t\t{'text_strings': ['جب کوئی خواب', 'آنکھوں میں سجایا نہیں جاتا', 'جب کوئی یاد', 'دل سے بھلایا نہیں جاتا', 'Latte Espresso', 'Cappuccino']}\n",
      "----------\n",
      "./images/cn/pexels-photo-2599543.jpeg\n",
      "SceneXplain: \t{'text_strings': ['為人演說不取於相如如', '持讀誦為人演說其福勝', '此經乃至四句', '『無量阿僧祗世界七', '不生活相發菩提', '句法應不是', '阿熊多羅二', '言法相酱如', '是見如是信解']}\n",
      "OpenAI:\t\t{'text_strings': ['مَنْ جَرّبَ المُجَرَّبَ عَقْلُهُ مُخَرّب', 'مَنْ تَتَبّعَ رَاحَتَهُ ضَيّعَ شَأنَهُ', 'لاتهرول وراء أحد فالذي يحبك', 'سيترك كل شيء ويأتي إليك']}\n",
      "----------\n",
      "./images/cn/pexels-photo-3603453.jpeg\n",
      "SceneXplain: \t{'text_strings': ['老门框廣為心明', '王', '卤', '1']}\n",
      "OpenAI:\t\t{'text_strings': ['جھیل کنارے بیٹھ کر اس نے یہ سوچا', 'میری آخری خواہش کیا ہے', 'Latte Espresso Capuccino']}\n",
      "----------\n",
      "./images/ja/free-photo-of-prohibition-sign-in-japanese.jpeg\n",
      "SceneXplain: \t{'text_strings': ['no smoking', 'no smoking on the road']}\n",
      "OpenAI:\t\t{'text_strings': ['چای تلخ می نوشم و به یاد تو نبودنت طعم', 'مرگ می دهد به روح و جانم', 'Latte Espress th', 'Cappuccino']}\n",
      "----------\n",
      "./images/ja/free-photo-of-illuminated-lantern-in-the-street.jpeg\n",
      "SceneXplain: \t{'text_strings': ['キリンラカー', 'こてつ象', '美子専門店']}\n",
      "OpenAI:\t\t{'text_strings': ['جاي خي بو سرر مره قه وه ب مره لب', 'لاته سبريسو كابتشينو اميريكانو']}\n",
      "----------\n",
      "./images/ja/pexels-photo-8366393.jpeg\n",
      "SceneXplain: \t{'text_strings': ['unknown Japanese text']}\n",
      "OpenAI:\t\t{'text_strings': ['ما زلت احبهم و هم كرهوني', 'ما زالوا يؤلموني و انا ادعي لهم', 'Latte Espresso Cappuccino Americano']}\n",
      "----------\n",
      "./images/ar/pexels-photo-11127113.jpeg\n",
      "SceneXplain: \t{'text_strings': [\"Men's Lies\", \"If They're Strong..\"]}\n",
      "OpenAI:\t\t{'text_strings': ['إن كنت تريد أن تعيش سعيداً،', 'اربط حياتك بأهداف وليس', 'بأشخاص أو أشياء']}\n",
      "----------\n",
      "./images/ar/free-photo-of-signs-around-entrance-on-seashore.jpeg\n",
      "SceneXplain: \t{'text_strings': []}\n",
      "OpenAI:\t\t{'text_strings': ['چای خوب است برای روح من', 'چای خوب است وردیه من', 'چای خوب است برای تو', 'Latte Espresso Cappuccino']}\n",
      "----------\n",
      "./images/ar/pexels-photo-14900332.jpeg\n",
      "SceneXplain: \t{'text_strings': ['Arabic text']}\n",
      "OpenAI:\t\t{'text_strings': ['جا ماندن', 'هم می تواند یک اتفاق شیرین باشد', 'مثل کتابی که دوستت برایت به امانت گذاشته است', 'Latte Espresso Cappuccino']}\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for file, sx_record, oa_record in zip(image_files, scenex_response, openai_response):\n",
    "    print(file)\n",
    "    sx_answer = json.loads(sx_record['i18n']['en'])\n",
    "    oa_answer = json.loads(oa_record.message.content)\n",
    "\n",
    "    print(f\"SceneXplain: \\t{sx_answer}\")\n",
    "    print(f\"OpenAI:\\t\\t{oa_answer}\")\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea2db6e-aa2a-4ba2-a97d-56df8246c7ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
