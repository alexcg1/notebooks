{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7d8c1f5-2dc8-4d8c-9b87-34a3850fc539",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1386df22-9315-4e26-9689-62f98fa8dcc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "!rm -rf notebooks\n",
    "!git clone https://github.com/alexcg1/notebooks\n",
    "\n",
    "if os.getcwd() != 'scenex-gpt4v':\n",
    "    os.chdir('notebooks/scenex/scenex-gpt4v')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be48c872-4acb-4b07-868d-c8cb408aa7b1",
   "metadata": {},
   "source": [
    "### Load API keys\n",
    "\n",
    "If you have `dotenv` installed and a `.env` file, the below code will load it from there. Otherwise you'll need to set `SCENEX_SECRET` and `OPENAI_API_KEY` environment variables manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8af7257-3d0b-4dde-a39b-f2909b164cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    print(\"Environment variables loaded from .env\")\n",
    "except ImportError:\n",
    "    os.environ['OPENAI_API_KEY'] = \"<your OpenAI key>\"\n",
    "    os.environ['SCENEX_SECRET'] = \"<your SceneXplain key>\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ffb26e-09e9-418a-850f-556e3616c449",
   "metadata": {},
   "source": [
    "## Pre-process images\n",
    "\n",
    "Convert all `webp` files to `jpeg`\n",
    "\n",
    "**Note:** No need to do this for existing images in repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ae4228-e64d-456f-a8e8-2f0db4f0c41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!find ./images -type f -name \"*.webp\" -exec mogrify -format jpeg {} \\;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "690a5191-761c-470c-8400-ae356a64a8ad",
   "metadata": {},
   "source": [
    "## Generate image list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4c1c5d-b46d-4e93-a7f4-c9669820dc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "filetypes = ['jpg', 'jpeg', 'png']\n",
    "file_path = './images/**/'\n",
    "image_files = []\n",
    "\n",
    "for filetype in filetypes:\n",
    "    image_files.extend(glob(f'{file_path}*.{filetype}'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8736e-f596-4c77-8cce-7ab3e02e87f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_files"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b67282c3-31bb-4956-bb88-5a13ba090246",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Define functions for SceneXplain and OpenAI I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf66d9f-587d-4d48-ba45-89e204f1999c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import json\n",
    "import base64\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8aa1ee1-1179-4d8e-976b-3fbe003b2f23",
   "metadata": {},
   "source": [
    "#### SceneXplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba9391b-6024-4f70-8fd2-088f49f47549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SceneX setup and functions\n",
    "\n",
    "SCENEX_SECRET=os.getenv('SCENEX_SECRET')\n",
    "\n",
    "scenex_headers = {\n",
    "    \"x-api-key\": f\"token {SCENEX_SECRET}\",\n",
    "    \"content-type\": \"application/json\",\n",
    "}\n",
    "\n",
    "ALGO = \"Jelly\"\n",
    "\n",
    "def image_to_data_uri(file_path):\n",
    "    with open(file_path, \"rb\") as image_file:\n",
    "        encoded_image = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "        return f\"data:image/png;base64,{encoded_image}\"\n",
    "        \n",
    "def generate_scenex_data(image_files, json_schema=None, question=None, features=[]):\n",
    "    data = {}\n",
    "    data['data'] = []\n",
    "\n",
    "    for file in image_files:\n",
    "        cid = file.split('/')[-1]\n",
    "        row = {\n",
    "            \"image\": image_to_data_uri(file),\n",
    "            \"features\": features,\n",
    "            \"algorithm\": ALGO,\n",
    "            \"cid\": cid\n",
    "        }\n",
    "\n",
    "        if question:\n",
    "            row[\"question\"] = question\n",
    "\n",
    "        if json_schema:\n",
    "            row[\"json_schema\"] = json_schema\n",
    "\n",
    "        data['data'].append(row)\n",
    "\n",
    "    return data\n",
    "\n",
    "def process_scenex(data):\n",
    "    connection = http.client.HTTPSConnection(\"api.scenex.jina.ai\")\n",
    "    connection.request(\"POST\", \"/v1/describe\", json.dumps(data), scenex_headers)\n",
    "    response = connection.getresponse()\n",
    "    response_data = response.read().decode(\"utf-8\")\n",
    "    \n",
    "    connection.close()\n",
    "\n",
    "    return json.loads(response_data)['result']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68b3dfc0-f77b-4d76-b056-b4d5fe71da3e",
   "metadata": {},
   "source": [
    "#### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0252a3-bede-4d54-9b56-30bd84582498",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8088723-5c21-4f2c-af01-765348c13823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI functions\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "def encode_openai_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        return base64.b64encode(image_file.read()).decode('utf-8')\n",
    "\n",
    "def generate_openai_data(image_files, text=\"\"):\n",
    "    output = []\n",
    "    \n",
    "    for file in image_files:\n",
    "        base64_image = f\"data:image/jpeg;base64,{encode_openai_image(file)}\"\n",
    "        data = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                # \"filename\": file,\n",
    "                 \"content\": [\n",
    "                    {\n",
    "                    \"type\": \"image_url\",\n",
    "                    \"image_url\": base64_image\n",
    "                    },\n",
    "                    {\n",
    "                    \"type\": \"text\",\n",
    "                    \"text\": text\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        ]\n",
    "        \n",
    "        output.extend(data)\n",
    "        \n",
    "    return output\n",
    "\n",
    "\n",
    "def process_openai(data):\n",
    "    output = []\n",
    "\n",
    "    for record in data:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-4-vision-preview\",\n",
    "            messages=[record],\n",
    "            max_tokens=1000,\n",
    "        )\n",
    "\n",
    "        output.append(response.choices[0])\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef2f7e3-42cb-46c9-9ade-b88e544685ed",
   "metadata": {},
   "source": [
    "## Basic captioning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15eb46c8-dbaa-480e-bb9b-e5dbc8453cb0",
   "metadata": {},
   "source": [
    "### SceneXplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aabfedcd-8df9-4b4e-b392-da43c703e6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_data = generate_scenex_data(image_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103b2820-2393-448c-9247-84b7af67d2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response = process_scenex(scenex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599146aa-57cb-419f-8afc-e718ca6d248d",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "869556e5-10db-4c65-bd0b-516e85863866",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb5faa4-5753-4628-a41d-b60faf7442e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_data = generate_openai_data(image_files, \"what is in this image?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "286be171-bdf7-4e5c-b16f-695109bea6d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response = process_openai(openai_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714d5d20-981d-4c01-8887-7d68837b6f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31df646e-0784-4d59-8705-63e29329a975",
   "metadata": {},
   "source": [
    "## Visual question answering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba35725b-f587-4222-9e48-a461fc11da6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'what does the text say in this image?'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7885bd69-b20b-4a91-ac64-519995141843",
   "metadata": {},
   "source": [
    "### SceneXplain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ef268f-1fc6-4dd3-a277-92310569ee00",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['question_answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae18ec38-cc56-46b2-9bd8-ad31363601e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_data = generate_scenex_data(image_files, question=question, features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c34f9b-c7c3-4608-96ad-0fa6e0090456",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response = process_scenex(scenex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99537e4d-ae3d-4cd6-95c8-eb8cb97db335",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed72dd62-d4d1-4be4-8001-b92459a78ce6",
   "metadata": {},
   "source": [
    "### OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe5cf36-87f8-45f1-8cd2-1c1d2549e376",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_data = generate_openai_data(image_files, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91dccc86-b93a-4ad8-bb84-4ae037dd1c8a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "openai_response = process_openai(openai_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0791a6ef-f2aa-431d-9da9-fbb9d531b04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4337351-0307-4388-a5f0-a13d76c4f47b",
   "metadata": {},
   "source": [
    "## Extract JSON from image\n",
    "\n",
    "We'll use SceneXplain's \"Extract JSON from Image\" feature to extract each text string and output to JSON that fits a strict schema.\n",
    "\n",
    "We'll also try a klugy way to do this with OpenAI, in the interests of fairness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021121c2-9f5a-425f-b57a-868ed9fc96fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = {\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"text_strings\": {\n",
    "      \"type\": \"array\",\n",
    "      \"description\": \"Every text string contained in the image. Consider all languages\"\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378ef9a-336f-41b4-8e74-caa63df82f10",
   "metadata": {},
   "source": [
    "### SceneX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e4cc3fa-0792-4ba4-96c2-e287fb7c790f",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\n",
    "    \"json\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78393558-5a7e-44ed-9c01-e271263a034e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_data = generate_scenex_data(image_files, json_schema=json.dumps(json_schema), features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f45bf1-5b39-43f1-9afb-3899daf22783",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response = process_scenex(scenex_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0aff10-0363-438f-96ee-4848b99194ff",
   "metadata": {},
   "source": [
    "### OpenAI\n",
    "\n",
    "We have to kluge it a bit by asking for JSON output as part of the question. This may not always provide reliably strict output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b62a39-0649-4fa9-bf34-40fe4b2a039e",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = f\"Extract the text strings from this image and populate a JSON that follows this schema:\\n\\n{str(json_schema)}. Return just the output JSON. Do not put it in a code block\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057fe81a-cfd1-484a-babe-64bfbad4a029",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_data = generate_openai_data(image_files, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc46cfe-c570-4f60-80e4-f4a60d32cbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response = process_openai(openai_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baecfc6c-3513-4421-ae67-e5a0777aaba8",
   "metadata": {},
   "source": [
    "### Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d924534b-185f-4c5b-9a1a-4763d4f39651",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, sx_record, oa_record in zip(image_files, scenex_response, openai_response):\n",
    "    print(file)\n",
    "    sx_answer = json.loads(sx_record['i18n']['en'])\n",
    "    oa_answer = json.loads(oa_record.message.content)\n",
    "\n",
    "    print(f\"SceneXplain: \\t{sx_answer}\")\n",
    "    print(f\"OpenAI:\\t\\t{oa_answer}\")\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3a476b-7c78-407e-a103-a199cbad5005",
   "metadata": {},
   "source": [
    "## Extract more complex JSON\n",
    "\n",
    "Now we'll extract:\n",
    "\n",
    "- A general description of the scene\n",
    "- All text objects. Each object will contain:\n",
    "    - The text string itself\n",
    "    - The (human-readable) language of the string\n",
    "    - The ISO 639-1 language code (e.g. `en-US`)\n",
    "    - An English translation of the string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e709ca09-0b32-4bd4-9697-015795c4a211",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = {\n",
    "  \"type\": \"object\",\n",
    "  \"properties\": {\n",
    "    \"alt_tag\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"a short and concise alt-tag for the image, so visually-impaired users can know what they're looking at\"\n",
    "    },\n",
    "    \"long_description\": {\n",
    "      \"type\": \"string\",\n",
    "      \"description\": \"description of the image. Up to 20 words.\"\n",
    "    },\n",
    "    \"text_strings\": {\n",
    "      \"type\": \"array\",\n",
    "      \"description\": \"list of all text strings in the image\"\n",
    "    },\n",
    "    \"languages\": {\n",
    "      \"type\": \"array\",\n",
    "      \"description\": \"all the languages used in the image\"\n",
    "    },\n",
    "    \"iso_codes\": {\n",
    "      \"type\": \"array\",\n",
    "      \"description\": \"the iso-639-1 code for the language of every string in the image\"\n",
    "    }\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7927fddc-fbfa-4386-ac79-4a5a184dc2b7",
   "metadata": {},
   "source": [
    "### SceneX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e57983-a775-4733-a6d5-9ab711675bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_data = generate_scenex_data(image_files, json_schema=json.dumps(json_schema), features=features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7794f16-5cd8-4ee8-99ea-7884adba4809",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenex_response = process_scenex(scenex_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e440fbf6-8f72-4f20-ba66-bd205cda31c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, sx_record in zip(image_files, scenex_response):\n",
    "    print(file)\n",
    "    try:\n",
    "        sx_answer = json.loads(sx_record['i18n']['en'])\n",
    "\n",
    "        \n",
    "        pprint(sx_answer)\n",
    "        print(\"-\"*10)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc359a40-3721-4408-a327-c0b74411e80f",
   "metadata": {},
   "source": [
    "### OpenAI\n",
    "\n",
    "We have to kluge it a bit by asking for JSON output as part of the question. This may not always provide reliably strict output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a04ddc63-1ae0-4c81-bdd7-c7d6d57bd67d",
   "metadata": {},
   "outputs": [],
   "source": [
    "question = f\"Extract the text strings from this image and populate a JSON that follows this schema:\\n\\n{str(json_schema)}. Return just the output JSON. Do not put it in a code block\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63639668-87c2-43e3-860a-bd57d9f1f8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_data = generate_openai_data(image_files, question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48007907-4859-4c05-a215-eda31a941eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "openai_response = process_openai(openai_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e2a19b-00da-4ef6-b400-b3be3957ac0b",
   "metadata": {},
   "source": [
    "### Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32180368-2f3a-4662-93ee-9d6b108560c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, sx_record, oa_record in zip(image_files, scenex_response, openai_response):\n",
    "    try:\n",
    "        sx_answer = json.loads(sx_record['i18n']['en'])\n",
    "        oa_answer = json.loads(oa_record.message.content)\n",
    "        print(file)\n",
    "    \n",
    "        print(\"SceneXplain\")\n",
    "        pprint(sx_answer)\n",
    "    \n",
    "        print('\\n')\n",
    "    \n",
    "        print(\"OpenAI\")\n",
    "        pprint(oa_answer)\n",
    "    except:\n",
    "        print(f\"{file} failed\")\n",
    "        \n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730cdc0c-8e67-4da1-a62b-272aafec3e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "for file, sx_record, oa_record in zip(image_files, scenex_response, openai_response):\n",
    "    try:\n",
    "        sx_answer = json.loads(sx_record['i18n']['en'])['text_strings']\n",
    "        oa_answer = json.loads(oa_record.message.content)['text_strings']\n",
    "        print(file)\n",
    "    \n",
    "        print(f\"SceneXplain:\\t{sx_answer}\")    \n",
    "        print(f\"OpenAI:\\t\\t{oa_answer}\")\n",
    "    except:\n",
    "        print(f\"{file} failed\")\n",
    "        \n",
    "    print(\"-\"*10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
